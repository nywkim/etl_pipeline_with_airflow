[2023-01-24T18:30:07.734+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: spotify_dag.spotify_etl manual__2023-01-24T18:30:03.247767+00:00 [queued]>
[2023-01-24T18:30:07.740+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: spotify_dag.spotify_etl manual__2023-01-24T18:30:03.247767+00:00 [queued]>
[2023-01-24T18:30:07.741+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-01-24T18:30:07.741+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 2
[2023-01-24T18:30:07.741+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-01-24T18:30:07.753+0000] {taskinstance.py:1383} INFO - Executing <Task(BranchPythonOperator): spotify_etl> on 2023-01-24 18:30:03.247767+00:00
[2023-01-24T18:30:07.756+0000] {standard_task_runner.py:55} INFO - Started process 5470 to run task
[2023-01-24T18:30:07.760+0000] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'spotify_dag', 'spotify_etl', 'manual__2023-01-24T18:30:03.247767+00:00', '--job-id', '279', '--raw', '--subdir', 'DAGS_FOLDER/airflow_dags.py', '--cfg-path', '/tmp/tmpj0gt26y7']
[2023-01-24T18:30:07.762+0000] {standard_task_runner.py:83} INFO - Job 279: Subtask spotify_etl
[2023-01-24T18:30:07.799+0000] {task_command.py:376} INFO - Running <TaskInstance: spotify_dag.spotify_etl manual__2023-01-24T18:30:03.247767+00:00 [running]> on host ip-172-31-26-59.ap-northeast-2.compute.internal
[2023-01-24T18:30:07.827+0000] {logging_mixin.py:120} WARNING - /home/ubuntu/.local/lib/python3.10/site-packages/airflow/utils/context.py:204 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2023-01-24T18:30:07.856+0000] {taskinstance.py:1590} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=nywkim@example.com
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=spotify_dag
AIRFLOW_CTX_TASK_ID=spotify_etl
AIRFLOW_CTX_EXECUTION_DATE=2023-01-24T18:30:03.247767+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-01-24T18:30:03.247767+00:00
[2023-01-24T18:30:12.354+0000] {credentials.py:1048} INFO - Found credentials from IAM Role: EC2_S3_Af
[2023-01-24T18:30:12.535+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 211, in execute
    branch = super().execute(context)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/ubuntu/airflow/spotify_dag/spotify_dags.py", line 89, in find_songs
    s3.upload_file(file_path, bucket, key)
  File "/usr/local/lib/python3.10/dist-packages/boto3/s3/inject.py", line 143, in upload_file
    return transfer.upload_file(
  File "/usr/local/lib/python3.10/dist-packages/boto3/s3/transfer.py", line 292, in upload_file
    future.result()
  File "/usr/local/lib/python3.10/dist-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/usr/local/lib/python3.10/dist-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/usr/local/lib/python3.10/dist-packages/s3transfer/tasks.py", line 139, in __call__
    return self._execute_main(kwargs)
  File "/usr/local/lib/python3.10/dist-packages/s3transfer/tasks.py", line 162, in _execute_main
    return_value = self._main(**kwargs)
  File "/usr/local/lib/python3.10/dist-packages/s3transfer/upload.py", line 758, in _main
    client.put_object(Bucket=bucket, Key=key, Body=body, **extra_args)
  File "/usr/local/lib/python3.10/dist-packages/botocore/client.py", line 530, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/botocore/client.py", line 919, in _make_api_call
    request_dict = self._convert_to_request_dict(
  File "/usr/local/lib/python3.10/dist-packages/botocore/client.py", line 987, in _convert_to_request_dict
    api_params = self._emit_api_params(
  File "/usr/local/lib/python3.10/dist-packages/botocore/client.py", line 1026, in _emit_api_params
    self.meta.events.emit(
  File "/usr/local/lib/python3.10/dist-packages/botocore/hooks.py", line 412, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/botocore/hooks.py", line 256, in emit
    return self._emit(event_name, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/botocore/hooks.py", line 239, in _emit
    response = handler(**kwargs)
  File "/usr/local/lib/python3.10/dist-packages/botocore/handlers.py", line 285, in validate_bucket_name
    raise ParamValidationError(report=error_msg)
botocore.exceptions.ParamValidationError: Parameter validation failed:
Invalid bucket name "s3://airflow-nk/": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2023-01-24T18:30:12.545+0000] {taskinstance.py:1401} INFO - Marking task as UP_FOR_RETRY. dag_id=spotify_dag, task_id=spotify_etl, execution_date=20230124T183003, start_date=20230124T183007, end_date=20230124T183012
[2023-01-24T18:30:12.556+0000] {standard_task_runner.py:100} ERROR - Failed to execute job 279 for task spotify_etl (Parameter validation failed:
Invalid bucket name "s3://airflow-nk/": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"; 5470)
[2023-01-24T18:30:12.586+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2023-01-24T18:30:12.605+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
